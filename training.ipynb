{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc901c95",
   "metadata": {},
   "source": [
    "# Training Demo\n",
    "This notebook shows training of a late fusion and a robust transfuser model. Make sure to run this from the root of the project directory. Please activate the environment provided by the requirements.txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d867e3",
   "metadata": {},
   "source": [
    "The entire code of the folders transfuser, leaderboard, latefusion, scenario_runner and tools is adapted from the transfuser Github repository: https://github.com/autonomousvision/transfuser.\n",
    "\n",
    "This notebook is adapted from transfuser/train.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1e835",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96282431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "from transfuser.config import GlobalConfig\n",
    "from transfuser.model import TransFuser\n",
    "from transfuser.data import CARLA_Data\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcedbb",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LEARNING_RATE = 1e-4\n",
    "LOG_DIR = 'log'\n",
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d00df95",
   "metadata": {},
   "source": [
    "If you want to train a robust model set `use_robust` to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1940f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_ROBUST = True\n",
    "\n",
    "if USE_ROBUST:\n",
    "    SENSOR_FAILURES = ['none', 'rgb', 'lidar']\n",
    "else:\n",
    "    SENSOR_FAILURES = ['none']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d96f4c",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac33a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "config = GlobalConfig()\n",
    "config.use_pseudolidar = False\n",
    "\n",
    "# Data\n",
    "train_set = CARLA_Data(root=config.train_data, config=config)\n",
    "val_set = CARLA_Data(root=config.val_data, config=config)\n",
    "\n",
    "dataloader_train = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "dataloader_val = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Model\n",
    "model = TransFuser(config, DEVICE, USE_ROBUST)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d937b059",
   "metadata": {},
   "source": [
    "## Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_train))\n",
    "\n",
    "# Input\n",
    "fronts_in = batch['fronts']\n",
    "lefts_in = batch['lefts']\n",
    "rights_in = batch['rights']\n",
    "rears_in = batch['rears']\n",
    "lidars_in = batch['lidars']\n",
    " \n",
    "# Labels\n",
    "command = batch['command']\n",
    "gt_velocity = batch['velocity']\n",
    "gt_steer = batch['steer']\n",
    "gt_throttle = batch['throttle']\n",
    "gt_brake = batch['brake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "# Plot formatting\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax1.title.set_text('RGB')\n",
    "ax2.title.set_text('LiDAR')\n",
    "ax1.title.set_font_properties({'size': 22})\n",
    "ax2.title.set_font_properties({'size': 22})\n",
    "\n",
    "ax1.imshow(fronts_in[0].squeeze().permute((1,2,0)))\n",
    "ax2.imshow(np.max(lidars_in[0].squeeze().numpy(), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca998877",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Command: {command.numpy()[0]}')\n",
    "print(f'Velocity: {gt_velocity.numpy()[0]}')\n",
    "print(f'Steering Angle: {gt_steer.numpy()[0]}')\n",
    "print(f'Throttle: {gt_throttle.numpy()[0]}')\n",
    "print(f'Brake: {gt_brake.numpy()[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ba41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(self, train_loss, val_loss, bestval, cur_epoch, cur_iter):\n",
    "\n",
    "    save_best = False\n",
    "    if val_loss[-1] <= bestval:\n",
    "        bestval = val_loss[-1]\n",
    "        save_best = True\n",
    "    \n",
    "    # Create a dictionary of all data to save\n",
    "    log_table = {\n",
    "        'epoch': cur_epoch,\n",
    "        'iter': cur_iter,\n",
    "        'bestval': bestval,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "    }\n",
    "\n",
    "    # Save ckpt for every epoch\n",
    "    torch.save(model.state_dict(), os.path.join(LOG_DIR, 'model_%d.pth'%self.cur_epoch))\n",
    "\n",
    "    # Save the recent model/optimizer states\n",
    "    torch.save(model.state_dict(), os.path.join(LOG_DIR, 'model.pth'))\n",
    "    torch.save(optimizer.state_dict(), os.path.join(LOG_DIR, 'recent_optim.pth'))\n",
    "\n",
    "    # Log other data corresponding to the recent model\n",
    "    with open(os.path.join(LOG_DIR, 'recent.log'), 'w') as f:\n",
    "        f.write(json.dumps(log_table))\n",
    "\n",
    "    tqdm.write('====== Saved recent model ======>')\n",
    "    \n",
    "    if save_best:\n",
    "        torch.save(model.state_dict(), os.path.join(LOG_DIR, 'best_model.pth'))\n",
    "        torch.save(optimizer.state_dict(), os.path.join(LOG_DIR, 'best_optim.pth'))\n",
    "        tqdm.write('====== Overwrote best model ======>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "cur_iter = 0\n",
    "bestval = 1e10\n",
    "for epoch in range(NUM_EPOCHS): \n",
    "\t####---------------- TRAINING -----------------####\n",
    "\tfor data in tqdm(dataloader_train):\n",
    "\t\tloss_epoch = 0.\n",
    "\t\tnum_batches = 0\n",
    "\t\tmodel.train()\n",
    "\t\t\n",
    "\t\t# create batch and move to GPU\n",
    "\t\tfronts_in = data['fronts']\n",
    "\t\tlefts_in = data['lefts']\n",
    "\t\trights_in = data['rights']\n",
    "\t\trears_in = data['rears']\n",
    "\t\tlidars_in = data['lidars']\n",
    "\t\tfronts = []\n",
    "\t\tlefts = []\n",
    "\t\trights = []\n",
    "\t\trears = []\n",
    "\t\tlidars = []\n",
    "\t\trgb_corrupted = False\n",
    "\t\tlidar_corrupted = False\n",
    "\t\tcurrent_batch_size = fronts_in[0].shape[0]\n",
    "\t\tfor i in range(config.seq_len):\n",
    "\t\t\tcurrent_sensor_failure_used = random.choice(SENSOR_FAILURES)\n",
    "\t\t\tgt_front = torch.zeros(current_batch_size, dtype=torch.float32)\n",
    "\t\t\tif current_sensor_failure_used == 'rgb' :\n",
    "\t\t\t\tpossible_fronts = [fronts_in[i], torch.zeros_like(fronts_in[i])]\n",
    "\t\t\t\tfront = torch.zeros_like(fronts_in[i])\n",
    "\t\t\t\tif torch.max(front) == 0:\n",
    "\t\t\t\t\trgb_corrupted = True\n",
    "\t\t\t\t\tgt_front = torch.ones(current_batch_size, dtype=torch.float32)\n",
    "\t\t\t\tfronts.append(front.to(DEVICE, dtype=torch.float32))\n",
    "\t\t\telse:\n",
    "\t\t\t\tfronts.append(fronts_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\t\t\tif not config.ignore_sides:\n",
    "\t\t\t\tlefts.append(lefts_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\t\t\t\trights.append(rights_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\t\t\tif not config.ignore_rear:\n",
    "\t\t\t\trears.append(rears_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\t\t\tgt_lidar = torch.zeros(current_batch_size, dtype=torch.float32)\n",
    "\t\t\tif current_sensor_failure_used == 'lidar' and not rgb_corrupted:\n",
    "\t\t\t\tpossible_lidars = [lidars_in[i], torch.zeros_like(lidars_in[i])]\n",
    "\t\t\t\tlidar = torch.zeros_like(lidars_in[i])\n",
    "\t\t\t\tlidars.append(lidar.to(DEVICE, dtype=torch.float32))\n",
    "\n",
    "\t\t\t\tif lidar.mean() == 0:\n",
    "\t\t\t\t\tlidar_corrupted = True\n",
    "\t\t\t\t\tgt_lidar = torch.ones(current_batch_size, dtype=torch.float32)\n",
    "\t\t\telse:\n",
    "\t\t\t\tlidars.append(lidars_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\n",
    "\t\tgt_both_working = torch.zeros(current_batch_size, dtype=torch.float32) if lidar_corrupted or rgb_corrupted else torch.ones(current_batch_size, dtype=torch.float32)\n",
    "\n",
    "\t\t# driving labels\n",
    "\t\tcommand = data['command'].to(DEVICE)\n",
    "\t\tgt_velocity = data['velocity'].to(DEVICE, dtype=torch.float32)\n",
    "\t\tgt_steer = data['steer'].to(DEVICE, dtype=torch.float32)\n",
    "\t\tgt_throttle = data['throttle'].to(DEVICE, dtype=torch.float32)\n",
    "\t\tgt_brake = data['brake'].to(DEVICE, dtype=torch.float32)\n",
    "\n",
    "\t\t# target point\n",
    "\t\ttarget_point = torch.stack(data['target_point'], dim=1).to(DEVICE, dtype=torch.float32)\n",
    "\t\t\n",
    "\t\tif USE_ROBUST:\n",
    "\t\t\tpred_wp, logits = model(fronts+lefts+rights+rears, lidars, target_point, gt_velocity)\n",
    "\t\telse:\n",
    "\t\t\tpred_wp = model(fronts+lefts+rights+rears, lidars, target_point, gt_velocity)\n",
    "\t\t\n",
    "\n",
    "\n",
    "\t\tif USE_ROBUST:\n",
    "\t\t\tgt_waypoints = [torch.stack(data['waypoints'][i], dim=1).to(DEVICE, dtype=torch.float32) for i in range(config.seq_len, len(data['waypoints']))]\n",
    "\t\t\tgt_waypoints = torch.stack(gt_waypoints, dim=1).to(DEVICE, dtype=torch.float32)\n",
    "\t\t\tgt_classification = torch.stack([gt_front, gt_lidar, gt_both_working], dim=1).to(DEVICE, dtype=torch.float32)\n",
    "\t\t\tloss = F.l1_loss(pred_wp, gt_waypoints, reduction='none').mean()\n",
    "\t\t\tclassification_loss = F.cross_entropy(logits, gt_classification)\n",
    "\t\t\ttotal_loss = sum([loss, classification_loss])\n",
    "\t\t\ttotal_loss.backward()\n",
    "\t\t\tloss_epoch += float(total_loss.item())\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tgt_waypoints = [torch.stack(data['waypoints'][i], dim=1).to(DEVICE, dtype=torch.float32) for i in range(config.seq_len, len(data['waypoints']))]\n",
    "\t\t\tgt_waypoints = torch.stack(gt_waypoints, dim=1).to(DEVICE, dtype=torch.float32)\n",
    "\t\t\ttotal_loss = F.l1_loss(pred_wp, gt_waypoints, reduction='none').mean()\n",
    "\t\t\ttotal_loss.backward()\n",
    "\t\t\tloss_epoch += float(total_loss.item())\n",
    "\n",
    "\n",
    "\t\tnum_batches += 1\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tcur_iter += 1\n",
    "\n",
    "\n",
    "\tloss_epoch = loss_epoch / num_batches\n",
    "\ttrain_loss.append(loss_epoch)\n",
    "\n",
    "\n",
    "\t####---------------- VALIDATION -----------------####\n",
    "\tmodel.eval()\n",
    "\n",
    "\twith torch.no_grad():\t\n",
    "\t\tnum_batches = 0\n",
    "\t\twp_epoch = 0.\n",
    "\t\tclassification_loss_epoch = 0.\n",
    "\n",
    "\t\t# Validation loop\n",
    "\t\tfor batch_num, data in enumerate(tqdm(dataloader_val), 0):\n",
    "\t\t\t\n",
    "\t\t\t# create batch and move to GPU\n",
    "\t\t\tfronts_in = data['fronts']\n",
    "\t\t\tlefts_in = data['lefts']\n",
    "\t\t\trights_in = data['rights']\n",
    "\t\t\trears_in = data['rears']\n",
    "\t\t\tlidars_in = data['lidars']\n",
    "\t\t\tfronts = []\n",
    "\t\t\tlefts = []\n",
    "\t\t\trights = []\n",
    "\t\t\trears = []\n",
    "\t\t\tlidars = []\n",
    "\t\t\tcurrent_batch_size = fronts_in[0].shape[0]\n",
    "\t\t\tfor i in range(config.seq_len):\n",
    "\t\t\t\tfronts.append(fronts_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\t\t\t\tif not config.ignore_sides:\n",
    "\t\t\t\t\tlefts.append(lefts_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\t\t\t\t\trights.append(rights_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\t\t\t\tif not config.ignore_rear:\n",
    "\t\t\t\t\trears.append(rears_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\t\t\t\tlidars.append(lidars_in[i].to(DEVICE, dtype=torch.float32))\n",
    "\n",
    "\t\t\t# driving labels\n",
    "\t\t\tcommand = data['command'].to(DEVICE)\n",
    "\t\t\tgt_velocity = data['velocity'].to(DEVICE, dtype=torch.float32)\n",
    "\t\t\tgt_steer = data['steer'].to(DEVICE, dtype=torch.float32)\n",
    "\t\t\tgt_throttle = data['throttle'].to(DEVICE, dtype=torch.float32)\n",
    "\t\t\tgt_brake = data['brake'].to(DEVICE, dtype=torch.float32)\n",
    "\t\t\tgt_lidar = torch.zeros(current_batch_size, dtype=torch.float32)\n",
    "\t\t\tgt_front = torch.zeros(current_batch_size, dtype=torch.float32)\n",
    "\t\t\tgt_both_working = torch.ones(current_batch_size, dtype=torch.float32)\n",
    "\n",
    "\t\t\t# target point\n",
    "\t\t\ttarget_point = torch.stack(data['target_point'], dim=1).to(DEVICE, dtype=torch.float32)\n",
    "\n",
    "\t\t\tif USE_ROBUST:\n",
    "\t\t\t\tpred_wp, logits = model(fronts+lefts+rights+rears, lidars, target_point, gt_velocity)\n",
    "\t\t\telse:\n",
    "\t\t\t\tpred_wp = model(fronts+lefts+rights+rears, lidars, target_point, gt_velocity, train=False)\n",
    "\n",
    "\t\t\tif USE_ROBUST:\n",
    "\t\t\t\tgt_waypoints = [torch.stack(data['waypoints'][i], dim=1).to(DEVICE, dtype=torch.float32) for i in range(config.seq_len, len(data['waypoints']))]\n",
    "\t\t\t\tgt_waypoints = torch.stack(gt_waypoints, dim=1).to(DEVICE, dtype=torch.float32)\n",
    "\t\t\t\tgt_classification = torch.stack([gt_front, gt_lidar, gt_both_working], dim=1).to(args.device, dtype=torch.float32)\n",
    "\t\t\t\tloss = F.l1_loss(pred_wp, gt_waypoints, reduction='none').mean()\n",
    "\t\t\t\tclassification_loss = F.cross_entropy(logits, gt_classification)\n",
    "\t\t\t\ttotal_loss = sum([loss, classification_loss])\n",
    "\t\t\t\twp_epoch += float(total_loss.item())\n",
    "\t\t\t\tclassification_loss_epoch += float(classification_loss.item())\n",
    "\t\t\t# wp_loss_epoch += float(total_loss.item())\n",
    "\t\t\t# classification_loss_epoch += float(total_loss.item())\n",
    "\t\t\telse:\n",
    "\t\t\t\tgt_waypoints = [torch.stack(data['waypoints'][i], dim=1).to(DEVICE, dtype=torch.float32) for i in range(config.seq_len, len(data['waypoints']))]\n",
    "\t\t\t\tgt_waypoints = torch.stack(gt_waypoints, dim=1).to(DEVICE, dtype=torch.float32)\n",
    "\t\t\t\twp_epoch += float(F.l1_loss(pred_wp, gt_waypoints, reduction='none').mean())\n",
    "\n",
    "\t\t\tnum_batches += 1\n",
    "\t\t\t\t\n",
    "\t\twp_loss = wp_epoch / float(num_batches)\n",
    "\t\tclassification_loss_final = classification_loss_epoch / float(num_batches)\n",
    "\t\ttqdm.write(f'Epoch {epoch:03d}, Batch {batch_num:03d}:' + f' Wp: {wp_loss:3.3f}')\n",
    "\n",
    "\t\t\n",
    "\t\tval_loss.append(wp_loss)\n",
    "\t\n",
    "\n",
    "\tsave(train_loss, val_loss, bestval, epoch, cur_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
